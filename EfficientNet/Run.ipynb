{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d1a08d-4229-4ebb-8454-edbb0c4f989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from flask import Flask, jsonify\n",
    "import threading\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "# Define the preprocessing function for TensorFlow (same as during training)\n",
    "def preprocess_image(image):\n",
    "    #img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert BGR to RGB For Efficient Net + Custom\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB (3 channels) For Dense Net\n",
    "    img = cv2.resize(img, (48, 48))  # Resize to model's expected input size\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return img\n",
    "\n",
    "\n",
    "@app.route(\"/data\", methods=[\"GET\"])\n",
    "def send_data():\n",
    "    global previous_emotion, current_emotion\n",
    "    if current_emotion != previous_emotion:\n",
    "        previous_emotion = current_emotion\n",
    "        output_data = {\"Emotion: \": current_emotion}\n",
    "        return jsonify(output_data)\n",
    "    else:\n",
    "        return jsonify(output_data)\n",
    "\n",
    "        \n",
    "def run_flask_app():\n",
    "    app.run(debug=False, use_reloader=False, port=5000)\n",
    "    \n",
    "# Load the trained TensorFlow model\n",
    "#model = load_model('emotion_detection_model.h5')\n",
    "#model = load_model('efficientnet_model.h5')\n",
    "model = load_model('densenet_model.h5')\n",
    "\n",
    "current_emotion = \"Neutral\"\n",
    "previous_emotion = \"Neutral\"\n",
    "# Starting the Flask server in a separate thread\n",
    "thread = threading.Thread(target=run_flask_app)\n",
    "thread.start()\n",
    "\n",
    "# Start webcam capture\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Emotion labels (adjust to match the labels your model uses)\n",
    "emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", 'Neutral','Sad','Surprise']\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()  # Capture a frame from the webcam\n",
    "    \n",
    "    # Preprocess the frame for the model\n",
    "    img = preprocess_image(frame)\n",
    "\n",
    "    # Runs model to get predictions\n",
    "    predictions = model.predict(img, verbose=0)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    predicted_emotion = emotion_labels[predicted_class]\n",
    "    current_emotion = predicted_emotion\n",
    "\n",
    "    # Display the predicted emotion on the frame\n",
    "    cv2.putText(frame, f'Emotion: {predicted_emotion}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Show the frame with emotion label\n",
    "    cv2.imshow('Emotion Recognition', frame)\n",
    "\n",
    "    # Exit the loop when the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6515ed3-2a5d-45a0-80c6-93b9d4ef384a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
