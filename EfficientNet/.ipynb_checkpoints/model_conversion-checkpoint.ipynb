{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa2d5be-a7c9-4434-a249-890d6b5873a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_dense_emotion\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_dense_emotion\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as TensorFlow SavedModel at {saved_model_dir}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "# Load the Keras model from the .h5 file\n",
    "#model = tf.keras.models.load_model('emotion_detection_model.h5')\n",
    "model = tf.keras.models.load_model('densenet_model.h5')\n",
    "\n",
    "saved_model_dir = 'saved_dense_emotion'\n",
    "tf.saved_model.save(model, saved_model_dir)\n",
    "\n",
    "print(\"Model saved as TensorFlow SavedModel at {saved_model_dir}\")\n",
    "\n",
    "#pip install numpy==1.23.5 --user\n",
    "#python -m tf2onnx.convert --saved-model saved_model_emotion --output emotion_model.onnx --opset 13\n",
    "#python -m tf2onnx.convert --saved-model saved_dense_emotion --output dense_model.onnx --opset 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77939837-7728-4790-b2df-215138f6462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.15800469, 0.04281884, 0.16146655, 0.1692985 , 0.17242318,\n",
      "        0.19188185, 0.10410638]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "session = ort.InferenceSession(\"dense_model.onnx\")\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "# Simulate random input\n",
    "random_input = np.random.rand(1, 48, 48, 3).astype(np.float32)\n",
    "pred = session.run([output_name], {input_name: random_input})\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9ebdf5-1094-43ac-88fc-5f41937d5f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Index: 5\n",
      "Predicted Emotion: Sad\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "probabilities = np.array([0.15800469, 0.04281884, 0.16146655, 0.1692985, 0.17242318, 0.19188185, 0.10410638])\n",
    "predicted_index = np.argmax(probabilities)\n",
    "print(\"Predicted Index:\", predicted_index)\n",
    "\n",
    "class_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
    "predicted_emotion = class_labels[predicted_index]\n",
    "print(\"Predicted Emotion:\", predicted_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "964963d3-5b5c-4c4d-9ad6-67d463810b25",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Resize the image to 48x48 (assuming model expects this size)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m image_resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Normalize the image if required (typically models expect values between 0 and 1)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# You might need to apply specific normalization (e.g., mean, std scaling)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m image_normalized \u001b[38;5;241m=\u001b[39m image_resized \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# scale to [0, 1] if required\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2  # OpenCV for image loading and preprocessing\n",
    "\n",
    "# Load the ONNX model\n",
    "session = ort.InferenceSession(\"dense_model.onnx\")\n",
    "\n",
    "# Get the model's input and output names\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = 'webcam_image.png'  # Change this to your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Resize the image to 48x48 (assuming model expects this size)\n",
    "image_resized = cv2.resize(image, (48, 48))\n",
    "\n",
    "# Normalize the image if required (typically models expect values between 0 and 1)\n",
    "# You might need to apply specific normalization (e.g., mean, std scaling)\n",
    "image_normalized = image_resized / 255.0  # scale to [0, 1] if required\n",
    "\n",
    "# If the model expects a specific channel order (RGB or BGR)\n",
    "# Convert the image from BGR (OpenCV default) to RGB\n",
    "image_rgb = cv2.cvtColor(image_normalized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Add batch dimension (1, 48, 48, 3)\n",
    "input_image = np.expand_dims(image_rgb, axis=0).astype(np.float32)\n",
    "\n",
    "# Run inference on the image\n",
    "pred = session.run([output_name], {input_name: input_image})\n",
    "\n",
    "# Print the prediction\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9dd2f-2da7-41ff-a1fc-89e47a6585a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
